# =============================================================================
# LCT Backend Environment Configuration
# Copy to .env and fill in your values.
# =============================================================================

# Database
DATABASE_URL=postgresql://lct_user:lct_password@localhost:5433/lct_dev

# --- Security (P0) -----------------------------------------------------------
# Set AUTH_TOKEN to require Bearer token auth on all non-health endpoints.
# Leave empty/unset for development (no auth enforced).
AUTH_TOKEN=

# Disable /api/import/from-url by default (SSRF risk). Set to true only on
# trusted networks where URL import is needed.
ENABLE_URL_IMPORT=false

# Request body size limits (bytes)
MAX_JSON_BYTES=1048576       # 1 MB
MAX_BODY_BYTES=52428800      # 50 MB

# Rate limits (requests per 60-second window, per IP)
RATE_LIMIT_EXPENSIVE=10      # LLM-calling endpoints (analyze, generate)
RATE_LIMIT_MUTATE=60         # POST/PUT/DELETE endpoints
RATE_LIMIT_READ=200          # GET endpoints

# Audio download token (optional; protects /api/conversations/{id}/audio)
AUDIO_DOWNLOAD_TOKEN=

# Logging - set to DEBUG only when investigating issues
LOG_LEVEL=INFO

# --- API Keys ----------------------------------------------------------------
ANTHROPIC_API_KEY=
CLAUDE_API_KEY=
GOOGLEAI_API_KEY=
GEMINI_API_KEY=
GEMINI_KEY=
OPENAI_API_KEY=
DEEPSEEK_API_KEY=
OPENROUTER_API_KEY=
PIAPI_API_KEY=
PERPLEXITY_API_KEY=
ASSEMBLYAI_API_KEY=
ASSEMBLYAI_WS_URL=wss://api.assemblyai.com/v2/realtime/ws

# --- Google Cloud Storage (optional) -----------------------------------------
GCS_BUCKET_NAME=
GCS_FOLDER=

# --- Environment --------------------------------------------------------------
ENVIRONMENT=development
DEBUG=true

# --- Local LLM (Tailscale / LM Studio) ---------------------------------------
DEFAULT_LLM_MODE=local
LOCAL_LLM_BASE_URL=http://100.81.65.74:1234
LOCAL_LLM_CHAT_MODEL=glm-4.6v-flash
LOCAL_LLM_EMBEDDING_MODEL=text-embedding-qwen3-embedding-8b
LOCAL_LLM_JSON_MODE=true
LOCAL_LLM_TIMEOUT_SECONDS=120

# API tracing for backend outbound calls (STT + LLM)
TRACE_API_CALLS=true
API_LOG_PREVIEW_CHARS=280

# --- Speaker Diarization ---------------------------------------------------
# Send diarize=true to WhisperX, extract speaker segments, prefix transcript
# with speaker labels for LLM. Requires WhisperX with diarization enabled.
STT_DIARIZE_ENABLED=false
